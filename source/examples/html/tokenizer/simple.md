# HTML Tokenizer Example

This article provides a detailed explanation of an HTML tokenizer example implemented in C, demonstrating the capabilities of the lexbor library through the file [lexbor/html/tokenizer/simple.c](https://github.com/lexbor/lexbor/blob/master/examples/lexbor/html/tokenizer/simple.c). This code is intended to parse a simple HTML string and display the tokens generated by the tokenizer.

## Code Overview

The main function of this code, `main`, initializes the tokenizer, sets a callback for token processing, and then processes a predefined HTML string. The tokenizer handles the parsing by breaking the HTML into tokens, which are processed by the `token_callback` function.

### Tokenization Process

1. **Initialization**: The tokenizer is created and initialized with `lxb_html_tokenizer_create()` and `lxb_html_tokenizer_init()`. If initialization fails, an error message is printed using the `FAILED` macro, which handles error reporting and exits the program.

2. **Token Callback**: The `token_callback` function is registered as a callback to handle tokens generated by the tokenizer. This function processes different types of tokens:
   - **End of File Token**: If the token indicates the end of the input, the function simply returns it.
   - **Text Token**: If it is a text token, the function prints the text content enclosed by the appropriate markers.
   - **HTML Tags**: For opening and closing tags, the function prints the tag name. If there are attributes, it prints them along with their values. The handling of attribute values takes care of different quoting styles (e.g., single or double quotes).

### Main Function Execution

The main logic begins with defining an HTML string using an array of characters. It prints the original HTML for clarity:

```c
const lxb_char_t data[] = "<div a='b' enabled> &copy; Hi<span c=\"d\" e=f>"
                              " my </span>friend</div>";
```

3. **Begin Tokenization**: After setting up the tokenizer and establishing the callback function, the tokenization process begins with `lxb_html_tokenizer_begin(tkz)`, which prepares the tokenizer to accept input.

4. **Input Chunk Processing**: The example HTML data is passed to the tokenizer using `lxb_html_tokenizer_chunk(tkz, data, (sizeof(data) - 1))`. The tokenizer processes this chunk of data, generating tokens as defined in the callback function.

5. **Ending Tokenization**: After processing the input, the tokenizer is finalized with `lxb_html_tokenizer_end(tkz)`, ensuring that all tokens are properly flushed and processed.

6. **Cleanup**: Finally, the tokenizer resources are released with `lxb_html_tokenizer_destroy(tkz)` to prevent memory leaks.

## Conclusion

The provided example illustrates the basic functionality of the lexbor HTML tokenizer. It demonstrates how to set up a tokenizer, process HTML data, and define a callback to handle tokenization events. This example can serve as a foundation for more complex HTML processing tasks using lexbor, which is designed to efficiently handle HTML parsing requirements.