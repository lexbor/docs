# CSS Syntax Tokenizer Example

This article provides an overview of the `print_raw.c` source file, which
implements a simple command-line tool for tokenizing CSS syntax using the Lexbor
library. The primary purpose of this code is to read a CSS file, tokenize its
contents, and print the tokens to the standard output. 

## Breakdown of Major Code Sections

### Usage Function

The `usage` function is defined to inform users about how to execute the program
properly. It outputs a simple message stating that the tool requires one
argument, which is the name of the file to process:

```c
static void
usage(void)
{
    fprintf(stderr, "print_raw <file>\n");
}
```

This function is called when the number of command line arguments (`argv`)
provided is incorrect. It helps to guide users in using the tool correctly.

### Main Function Logic

The `main` function serves as the entry point of the program. It starts by
checking if the user has provided exactly one argument:

```c
if (argc != 2) {
    usage();
    FAILED("Invalid number of arguments");
}
```

If this condition is not met, the `usage` function is invoked to display the
correct usage. The `FAILED` macro indicates an error state, although its
definition is not shown in this excerpt.

### Reading the CSS File

The next step involves reading the CSS file specified by the user. The function
`lexbor_fs_file_easy_read` attempts to read the file into memory:

```c
css = lexbor_fs_file_easy_read((const lxb_char_t *) argv[1], &css_len);
if (css == NULL) {
    FAILED("Failed to read CSS file");
}
```

If the reading process fails, the program terminates by invoking the `FAILED`
macro once again to report the issue.

### Tokenization Process

The tokenization process begins with the creation of a tokenizer instance:

```c
tkz = lxb_css_syntax_tokenizer_create();
status = lxb_css_syntax_tokenizer_init(tkz);
```

After creating the tokenizer, it is initialized with the
`lxb_css_syntax_tokenizer_init` function. If the initialization does not
succeed, an error message is printed, and the program enters the cleanup phase.

The following block of code sets the tokenizer's buffer to contain the CSS
content read from the file:

```c
tkz->with_comment = true;

lxb_css_syntax_tokenizer_buffer_set(tkz, css, css_len);
```

The `with_comment` flag indicates whether comments should be included in the
tokenization process.

### Processing Tokens

The main loop of the `main` function processes the tokens generated by the
tokenizer:

```c
do {
    token = lxb_css_syntax_token(tkz);
    if (token == NULL) {
        PRINT("Failed to parse CSS");
        goto failed;
    }

    colorize_cb(token);

    type = lxb_css_syntax_token_type(token);

    lxb_css_syntax_token_consume(tkz);
}
while (type != LXB_CSS_SYNTAX_TOKEN__EOF);
```

Within this loop, a token is fetched, and if it cannot be retrieved, an error
message is printed. The `colorize_cb` function is called to handle the output
for each token. After processing the token, its type is checked, and it is
consumed for the next iteration.

### Cleanup Phase

After all tokens have been processed, the program cleans up by destroying the
tokenizer instance and freeing any allocated memory:

```c
lxb_css_syntax_tokenizer_destroy(tkz);
lexbor_free(css);
```

Finally, if no errors occurred during processing, the program returns
`EXIT_SUCCESS`. In case of failure, it follows a similar cleanup procedure but
returns `EXIT_FAILURE`.

## Conclusion

The `print_raw.c` implementation demonstrates how to leverage the Lexbor library
for CSS syntax tokenization. By following a structured approach, it effectively
reads CSS content, processes it into tokens, and provides robust error handling.
This example serves as a foundation for further exploration of CSS parsing and
analysis using Lexbor.